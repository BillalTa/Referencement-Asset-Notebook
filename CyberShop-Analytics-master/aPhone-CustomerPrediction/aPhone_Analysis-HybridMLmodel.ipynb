{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis & Prediction: Customer Likelihood to buy aPhone\n",
    "- - -\n",
    "- Build Machine Learning Model of Customer Likelihood to buy aPhone\n",
    "- Publish & Deploy Model Locally or to Cloud-based Watson Machine Learning Service in Bluemix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize project and environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.SparkContext\n",
    "import org.apache.spark.SparkConf\n",
    "\n",
    "// MLRepositoryClient won't load remote models correctly without running in local mode\n",
    "sc.stop()\n",
    "val conf1 = new SparkConf().setAppName(\"spark_context\").setMaster(\"local[*]\")\n",
    "val scl = new SparkContext(conf1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> Note: Only run the cell above when you run this notebook the first time after you create it, or whenever you restart the kernel. If you receive error about \"Only one SparkContext may be running in this JVM\", that is expected, restart kernel and rerun.  When re-running this notebook, select this cell and \"Run All Below\"</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Brunel and ML Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting download from https://brunelvis.org/jar/spark-kernel-brunel-all-2.3.jar\n",
      "Finished download of spark-kernel-brunel-all-2.3.jar\n"
     ]
    }
   ],
   "source": [
    "%AddJar -magic https://brunelvis.org/jar/spark-kernel-brunel-all-2.3.jar -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "//import libraries\n",
    "import org.apache.spark.{SparkConf, SparkContext, SparkFiles}\n",
    "import org.apache.spark.sql.{SQLContext, SparkSession, Row}\n",
    "import org.apache.spark.SparkFiles\n",
    "\n",
    "import org.apache.spark.ml.feature.{StringIndexer, IndexToString, VectorIndexer, VectorAssembler}\n",
    "import org.apache.spark.ml.regression.LinearRegression\n",
    "import org.apache.spark.ml.classification.{LogisticRegression, DecisionTreeClassifier}\n",
    "import org.apache.spark.ml.evaluation.BinaryClassificationEvaluator\n",
    "import org.apache.spark.ml.{Pipeline, PipelineStage}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data from CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+----------+----------+------+--------+------------+------------+------+\n",
      "|Gender|AgeGroup| Education|Profession|Income|Switcher|LastPurchase|Annual_Spend|APhone|\n",
      "+------+--------+----------+----------+------+--------+------------+------------+------+\n",
      "|     F|   45-54|   Masters|    Lawyer|114073|       0|           3|      1211.0|   1.0|\n",
      "|     M|   35-44|   Masters| Performer|186464|       0|           5|       382.0|   0.0|\n",
      "|     M|   55-64|   Masters|    Doctor|237237|       0|           4|      1440.0|   1.0|\n",
      "|     F|   18-24|HighSchool| Secretary| 18800|       1|           1|       546.0|   0.0|\n",
      "|     F|   55-64| Bachelors|     Nurse| 61742|       0|           4|       741.0|   0.0|\n",
      "+------+--------+----------+----------+------+--------+------------+------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import org.apache.spark.sql.SQLContext\n",
    "val sqlContext = new SQLContext(scl)\n",
    "\n",
    "// Add data asset from file system\n",
    "val phoneSales = sqlContext.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").option(\"mode\", \"DROPMALFORMED\").csv(\"../datasets/aPhone-Customers.csv\")\n",
    "phoneSales.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+----------+----------+------+--------+------------+------------+-----+\n",
      "|GENDER|AGEGROUP| EDUCATION|PROFESSION|INCOME|SWITCHER|LASTPURCHASE|ANNUAL_SPEND|label|\n",
      "+------+--------+----------+----------+------+--------+------------+------------+-----+\n",
      "|     F|   45-54|   Masters|    Lawyer|114073|       0|           3|      1211.0|  1.0|\n",
      "|     M|   35-44|   Masters| Performer|186464|       0|           5|       382.0|  0.0|\n",
      "|     M|   55-64|   Masters|    Doctor|237237|       0|           4|      1440.0|  1.0|\n",
      "|     F|   18-24|HighSchool| Secretary| 18800|       1|           1|       546.0|  0.0|\n",
      "|     F|   55-64| Bachelors|     Nurse| 61742|       0|           4|       741.0|  0.0|\n",
      "+------+--------+----------+----------+------+--------+------------+------------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- GENDER: string (nullable = true)\n",
      " |-- AGEGROUP: string (nullable = true)\n",
      " |-- EDUCATION: string (nullable = true)\n",
      " |-- PROFESSION: string (nullable = true)\n",
      " |-- INCOME: integer (nullable = true)\n",
      " |-- SWITCHER: integer (nullable = true)\n",
      " |-- LASTPURCHASE: integer (nullable = true)\n",
      " |-- ANNUAL_SPEND: double (nullable = true)\n",
      " |-- label: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8301"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "import org.apache.spark.sql.functions._ \n",
    "\n",
    "val toDouble = udf {x: Integer => if(x != null && x == 1) 1.0 else 0.0}\n",
    "val aphoneIndicator = udf {phone: String => if(phone.equals(\"A-phone\")) 1.0 else 0.0}\n",
    "\n",
    "val phoneSalesData = phoneSales.select(\"GENDER\", \"AGEGROUP\", \"EDUCATION\", \"PROFESSION\", \"INCOME\", \"SWITCHER\", \"LASTPURCHASE\", \"ANNUAL_SPEND\", \"APHONE\").\n",
    "                           withColumn(\"label\", toDouble(col(\"APHONE\"))).drop(\"APHONE\")\n",
    "\n",
    "phoneSalesData.show(5)\n",
    "phoneSalesData.printSchema()\n",
    "phoneSalesData.count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting into training and testing data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data set\n",
      "+------+--------+---------+----------+------+--------+------------+------------+-----+\n",
      "|GENDER|AGEGROUP|EDUCATION|PROFESSION|INCOME|SWITCHER|LASTPURCHASE|ANNUAL_SPEND|label|\n",
      "+------+--------+---------+----------+------+--------+------------+------------+-----+\n",
      "|     F|   18-24|Associate| Architect| 47131|       0|           2|      1417.0|  1.0|\n",
      "|     F|   18-24|Associate|     Clerk|  8041|       0|           5|       573.0|  0.0|\n",
      "|     F|   18-24|Associate|     Clerk| 10998|       1|           2|       746.0|  0.0|\n",
      "|     F|   18-24|Associate|     Clerk| 14131|       1|           2|       381.0|  0.0|\n",
      "|     F|   18-24|Associate|     Clerk| 21128|       0|           4|       582.0|  0.0|\n",
      "+------+--------+---------+----------+------+--------+------------+------------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "Testing data set\n",
      "+------+--------+---------+----------+------+--------+------------+------------+-----+\n",
      "|GENDER|AGEGROUP|EDUCATION|PROFESSION|INCOME|SWITCHER|LASTPURCHASE|ANNUAL_SPEND|label|\n",
      "+------+--------+---------+----------+------+--------+------------+------------+-----+\n",
      "|     F|   18-24|Associate|     Clerk| 14219|       1|           1|       516.0|  0.0|\n",
      "|     F|   18-24|Associate|   Manager| 45306|       1|           1|       970.0|  1.0|\n",
      "|     F|   18-24|Associate| Secretary| 15592|       1|           1|       717.0|  0.0|\n",
      "|     F|   18-24|Associate|   Student|  9890|       1|           1|       753.0|  0.0|\n",
      "|     F|   18-24|Associate|   Student| 10138|       1|           2|       553.0|  0.0|\n",
      "+------+--------+---------+----------+------+--------+------------+------------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "1652\n"
     ]
    }
   ],
   "source": [
    "val train = 0.80\n",
    "val test = 0.20\n",
    "\n",
    "//Split the data into training data set, testing data set, and validation data set\n",
    "\n",
    "val splits = phoneSalesData.randomSplit(Array(train, test), seed = 17L)\n",
    "\n",
    "val trainingDF = splits(0)\n",
    "val testDF = splits(1)\n",
    "\n",
    "println(\"Training data set\")\n",
    "trainingDF.show(5)\n",
    "\n",
    "println(\"Testing data set\")\n",
    "testDF.show(5)\n",
    "println(testDF.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.ml.feature.{StringIndexer, IndexToString, VectorIndexer, VectorAssembler}\n",
    "\n",
    "//Feature definition\n",
    "val genderIndexer = new StringIndexer().setInputCol(\"GENDER\").setOutputCol(\"GENDER_CODE\")\n",
    "val ageGroupIndexer = new StringIndexer().setInputCol(\"AGEGROUP\").setOutputCol(\"AGE_GROUP_CODE\")\n",
    "val professionIndexer = new StringIndexer().setInputCol(\"PROFESSION\").setOutputCol(\"PROFESSION_CODE\")\n",
    "val educationIndexer = new StringIndexer().setInputCol(\"EDUCATION\").setOutputCol(\"EDUCATION_CODE\")\n",
    "\n",
    "val featuresAssembler = new VectorAssembler().setInputCols(Array(\"INCOME\",\n",
    "                                                                 \"GENDER_CODE\",\n",
    "                                                                 \"AGE_GROUP_CODE\",\n",
    "                                                                 \"PROFESSION_CODE\", \n",
    "                                                                 \"EDUCATION_CODE\",\n",
    "                                                                 \"ANNUAL_SPEND\",\n",
    "                                                                 \"SWITCHER\",\n",
    "                                                                 \"LASTPURCHASE\")).setOutputCol(\"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assembling a pipeline with logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.ml.classification.{LogisticRegression, DecisionTreeClassifier}\n",
    "\n",
    "//Using Logistic Regression\n",
    "val lr = new LogisticRegression().setRegParam(0.01).setLabelCol(\"label\").setFeaturesCol(\"features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.ml.{Pipeline, PipelineStage}\n",
    "\n",
    "\n",
    "//Cognitive Assistant for Data Scientists - predict model performance based on sampled data\n",
    "val pipeline = new Pipeline().setStages(Array(genderIndexer, \n",
    "                                              ageGroupIndexer, \n",
    "                                              professionIndexer,\n",
    "                                              educationIndexer,\n",
    "                                              featuresAssembler,\n",
    "                                              lr))\n",
    "val newModel = pipeline.fit(trainingDF)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using DataFrame-based API for assessing performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "areaUnderROC: 0.9629843009364488\n",
      "+------------------+-------------------+\n",
      "|         threshold|          F-Measure|\n",
      "+------------------+-------------------+\n",
      "|0.9884018841317078| 0.0684326710816777|\n",
      "|0.9730702953731861|0.12886048988285412|\n",
      "|0.9663727171800365|0.18415637860082304|\n",
      "|0.9588561238477399|0.23582089552238805|\n",
      "| 0.952242262751719|0.27745664739884396|\n",
      "+------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "best threshold:0.32415690502632283\n"
     ]
    }
   ],
   "source": [
    "import org.apache.spark.ml.classification.{BinaryLogisticRegressionSummary, LogisticRegressionModel}\n",
    "\n",
    "// Extract the summary from the LogisticRegressionModel instance \n",
    "val lrModel = newModel.stages(5).asInstanceOf[LogisticRegressionModel]\n",
    "val trainingSummary = lrModel.summary\n",
    "\n",
    "// Metrics for binary classification\n",
    "val binarySummary = trainingSummary.asInstanceOf[BinaryLogisticRegressionSummary]\n",
    "\n",
    "// The receiver-operating characteristic curve and area under the ROC curve\n",
    "val roc = binarySummary.roc\n",
    "println(s\"areaUnderROC: ${binarySummary.areaUnderROC}\")\n",
    "\n",
    "// Example of optimizing logistic regression model to maximize F-measure\n",
    "val fMeasure = binarySummary.fMeasureByThreshold\n",
    "fMeasure.show(5)\n",
    "val maxFMeasure = fMeasure.select(max(\"F-Measure\")).head().getDouble(0)\n",
    "val bestThreshold = fMeasure.where(fMeasure(\"F-Measure\") === maxFMeasure).\n",
    "  select(\"threshold\").head().getDouble(0)\n",
    "println(s\"best threshold:${bestThreshold}\")\n",
    "\n",
    "val updatedModel = lrModel.setThreshold(bestThreshold)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC curve based on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "         <link rel=\"stylesheet\" type=\"text/css\" href=\"/dsx-jupyter/ibmdsxuser-1010/1506603270372/nbextensions/brunel_ext/brunel.2.3.css\" charset=\"utf-8\">\n",
       "         <link rel=\"stylesheet\" type=\"text/css\" href=\"/dsx-jupyter/ibmdsxuser-1010/1506603270372/nbextensions/brunel_ext/sumoselect.css\" charset=\"utf-8\">\n",
       "         <style>  </style>\n",
       "         <div id=\"controlsId9cecf407-3405-4aa8-9204-b43f7c470f54\" class=\"brunel\"/>\n",
       "<svg id=\"visida724185d-e835-4d3d-8065-baac2dd3ffeb\" width=\"500\" height=\"400\"></svg>\n",
       "\n",
       "<script>\n",
       "require.config({\n",
       "            waitSeconds: 60,\n",
       "            paths: {\n",
       "                'd3': '//cdnjs.cloudflare.com/ajax/libs/d3/4.2.1/d3.min',\n",
       "                'topojson' : '//cdnjs.cloudflare.com/ajax/libs/topojson/1.6.20/topojson.min',\n",
       "                'brunel' : '/dsx-jupyter/ibmdsxuser-1010/1506603270372/nbextensions/brunel_ext/brunel.2.3.min',\n",
       "                'brunelControls' : '/dsx-jupyter/ibmdsxuser-1010/1506603270372/nbextensions/brunel_ext/brunel.controls.2.3.min'\n",
       "            },\n",
       "\n",
       "            shim: {\n",
       "               'brunel' : {\n",
       "                    exports: 'BrunelD3',\n",
       "                    deps: ['d3', 'topojson'],\n",
       "                    init: function() {\n",
       "                       return {\n",
       "                         BrunelD3 : BrunelD3,\n",
       "                         BrunelData : BrunelData\n",
       "                      }\n",
       "                    }\n",
       "                },\n",
       "               'brunelControls' : {\n",
       "                    exports: 'BrunelEventHandlers',\n",
       "                    init: function() {\n",
       "                       return {\n",
       "                         BrunelEventHandlers: BrunelEventHandlers,\n",
       "                         BrunelJQueryControlFactory: BrunelJQueryControlFactory\n",
       "                      }\n",
       "                    }\n",
       "                }\n",
       "\n",
       "            }\n",
       "\n",
       "        });\n",
       "\n",
       "        require([\"d3\"], function(d3) {\n",
       "        require([\"brunel\", \"brunelControls\"], function(brunel, brunelControls) {\n",
       "\n",
       "            function  BrunelVis(visId) {\n",
       "  \"use strict\";                                                                       // strict mode\n",
       "  var datasets = [],                                      // array of datasets for the original data\n",
       "      pre = function(d, i) { return d },                         // default pre-process does nothing\n",
       "      post = function(d, i) { return d },                       // default post-process does nothing\n",
       "      transitionTime = 200,                                        // transition time for animations\n",
       "      charts = [],                                                       // the charts in the system\n",
       "      vis = d3.select('#' + visId).attr('class', 'brunel');                     // the SVG container\n",
       "\n",
       "  BrunelD3.addDefinitions(vis);                                   // ensure standard symbols present\n",
       "\n",
       "  // Define chart #1 in the visualization //////////////////////////////////////////////////////////\n",
       "\n",
       "  charts[0] = function(parentNode, filterRows) {\n",
       "    var geom = BrunelD3.geometry(parentNode || vis.node(), 0, 0, 1, 1, 22, 43, 37, 13),\n",
       "      elements = [];                                              // array of elements in this chart\n",
       "\n",
       "    // Define groups for the chart parts ///////////////////////////////////////////////////////////\n",
       "\n",
       "    var chart =  vis.append('g').attr('class', 'chart1')\n",
       "      .attr('transform','translate(' + geom.chart_left + ',' + geom.chart_top + ')');\n",
       "    var overlay = chart.append('g').attr('class', 'element').attr('class', 'overlay');\n",
       "    var zoom = d3.zoom().scaleExtent([1/3,3]);\n",
       "    var zoomNode = overlay.append('rect').attr('class', 'overlay')\n",
       "      .attr('x', geom.inner_left).attr('y', geom.inner_top)\n",
       "      .attr('width', geom.inner_rawWidth).attr('height', geom.inner_rawHeight)\n",
       "      .style('cursor', 'move').call(zoom)\n",
       "      .node();\n",
       "    zoomNode.__zoom = d3.zoomIdentity;\n",
       "    chart.append('rect').attr('class', 'background').attr('width', geom.chart_right-geom.chart_left).attr('height', geom.chart_bottom-geom.chart_top);\n",
       "    var interior = chart.append('g').attr('class', 'interior zoomNone')\n",
       "      .attr('transform','translate(' + geom.inner_left + ',' + geom.inner_top + ')')\n",
       "      .attr('clip-path', 'url(#clip_visida724185d-e835-4d3d-8065-baac2dd3ffeb_chart1_inner)');\n",
       "    interior.append('rect').attr('class', 'inner').attr('width', geom.inner_width).attr('height', geom.inner_height);\n",
       "    var gridGroup = interior.append('g').attr('class', 'grid');\n",
       "    var axes = chart.append('g').attr('class', 'axis')\n",
       "      .attr('transform','translate(' + geom.inner_left + ',' + geom.inner_top + ')');\n",
       "    vis.append('clipPath').attr('id', 'clip_visida724185d-e835-4d3d-8065-baac2dd3ffeb_chart1_inner').append('rect')\n",
       "      .attr('x', 0).attr('y', 0)\n",
       "      .attr('width', geom.inner_rawWidth+1).attr('height', geom.inner_rawHeight+1);\n",
       "    chart.append('text').attr('class', 'title header').text('ROC').style('text-anchor', 'middle')\n",
       "      .attr('x','50%')\n",
       "      .attr('y',2).attr('dy','0.8em');\n",
       "\n",
       "    // Scales //////////////////////////////////////////////////////////////////////////////////////\n",
       "\n",
       "    var scale_x = d3.scaleLinear().domain([0, 1.0000001])\n",
       "      .range([0, geom.inner_width]);\n",
       "    var scale_inner = d3.scaleLinear().domain([0,1])\n",
       "      .range([-0.5, 0.5]);\n",
       "    var scale_y = d3.scaleLinear().domain([0, 1.0000001])\n",
       "      .range([geom.inner_height, 0]);\n",
       "    var base_scales = [scale_x, scale_y];                           // untransformed original scales\n",
       "\n",
       "    // Axes ////////////////////////////////////////////////////////////////////////////////////////\n",
       "\n",
       "    axes.append('g').attr('class', 'x axis')\n",
       "      .attr('transform','translate(0,' + geom.inner_rawHeight + ')')\n",
       "      .attr('clip-path', 'url(#clip_visida724185d-e835-4d3d-8065-baac2dd3ffeb_chart1_haxis)');\n",
       "    vis.append('clipPath').attr('id', 'clip_visida724185d-e835-4d3d-8065-baac2dd3ffeb_chart1_haxis').append('polyline')\n",
       "      .attr('points', '-1,-1000, -1,-1 -5,5, -1000,5, -100,1000, 10000,1000 10000,-1000');\n",
       "    axes.select('g.axis.x').append('text').attr('class', 'title').text('False Positive Rate').style('text-anchor', 'middle')\n",
       "      .attr('x',geom.inner_rawWidth/2)\n",
       "      .attr('y', geom.inner_bottom - 2.0).attr('dy','-0.27em');\n",
       "    axes.append('g').attr('class', 'y axis')\n",
       "      .attr('clip-path', 'url(#clip_visida724185d-e835-4d3d-8065-baac2dd3ffeb_chart1_vaxis)');\n",
       "    vis.append('clipPath').attr('id', 'clip_visida724185d-e835-4d3d-8065-baac2dd3ffeb_chart1_vaxis').append('polyline')\n",
       "      .attr('points', '-1000,-10000, 10000,-10000, 10000,' + (geom.inner_rawHeight+1) + ', -1,' + (geom.inner_rawHeight+1) + ', -1,' + (geom.inner_rawHeight+5) + ', -1000,' + (geom.inner_rawHeight+5) );\n",
       "    axes.select('g.axis.y').append('text').attr('class', 'title').text('True Positive Rate').style('text-anchor', 'middle')\n",
       "      .attr('x',-geom.inner_rawHeight/2)\n",
       "      .attr('y', 4-geom.inner_left).attr('dy', '0.7em').attr('transform', 'rotate(270)');\n",
       "\n",
       "    var axis_bottom = d3.axisBottom(scale_x).ticks(Math.min(10, Math.round(geom.inner_width / 33.0)));\n",
       "    var axis_left = d3.axisLeft(scale_y).ticks(Math.min(10, Math.round(geom.inner_width / 20)));\n",
       "\n",
       "    function buildAxes(time) {\n",
       "      var axis_x = axes.select('g.axis.x');\n",
       "      BrunelD3.transition(axis_x, time).call(axis_bottom.scale(scale_x));\n",
       "      var axis_y = axes.select('g.axis.y');\n",
       "      BrunelD3.transition(axis_y, time).call(axis_left.scale(scale_y));\n",
       "      BrunelD3.makeGrid(gridGroup, scale_x, geom.inner_height, true );\n",
       "      BrunelD3.makeGrid(gridGroup, scale_y, geom.inner_width, false );\n",
       "    }\n",
       "    zoom.on('zoom', function(t, time) {\n",
       "        t = t ||BrunelD3.restrictZoom(d3.event.transform, geom, this);\n",
       "        scale_x = t.rescaleX(base_scales[0]);\n",
       "        scale_y = t.rescaleY(base_scales[1]);\n",
       "        zoomNode.__zoom = t;\n",
       "        interior.attr('class', 'interior ' + BrunelD3.zoomLabel(t.k));;\n",
       "        build(time || -1);\n",
       "    });\n",
       "\n",
       "    // Define element #1 ///////////////////////////////////////////////////////////////////////////\n",
       "\n",
       "    elements[0] = function() {\n",
       "      var original, processed,                           // data sets passed in and then transformed\n",
       "        element, data,                                 // brunel element information and brunel data\n",
       "        selection, merged;                                      // d3 selection and merged selection\n",
       "      var elementGroup = interior.append('g').attr('class', 'element1'),\n",
       "        main = elementGroup.append('g').attr('class', 'main'),\n",
       "        labels = BrunelD3.undoTransform(elementGroup.append('g').attr('class', 'labels').attr('aria-hidden', 'true'), elementGroup);\n",
       "\n",
       "      function makeData() {\n",
       "        original = datasets[0];\n",
       "        if (filterRows) original = original.retainRows(filterRows);\n",
       "        processed = pre(original, 0)\n",
       "          .sortRows('FPR:ascending');\n",
       "        processed = post(processed, 0);\n",
       "        var f0 = processed.field('FPR'),\n",
       "          f1 = processed.field('TPR'),\n",
       "          f2 = processed.field('#row'),\n",
       "          f3 = processed.field('#selection');\n",
       "        var keyFunc = function(d) { return 'ALL' };\n",
       "        data = {\n",
       "          FPR:          function(d) { return f0.value(d.row) },\n",
       "          TPR:          function(d) { return f1.value(d.row) },\n",
       "          $row:         function(d) { return f2.value(d.row) },\n",
       "          $selection:   function(d) { return f3.value(d.row) },\n",
       "          FPR_f:        function(d) { return f0.valueFormatted(d.row) },\n",
       "          TPR_f:        function(d) { return f1.valueFormatted(d.row) },\n",
       "          $row_f:       function(d) { return f2.valueFormatted(d.row) },\n",
       "          $selection_f: function(d) { return f3.valueFormatted(d.row) },\n",
       "          _split:       function(d) { return 'ALL' },\n",
       "          _key:         keyFunc,\n",
       "          _rows:        BrunelD3.makeRowsWithKeys(keyFunc, processed.rowCount())\n",
       "        };\n",
       "      }\n",
       "\n",
       "      // Build element from data ///////////////////////////////////////////////////////////////////\n",
       "\n",
       "      function build(transitionMillis) {\n",
       "        element = elements[0];\n",
       "        var w = geom.default_point_size;\n",
       "        var x = function(d) { return scale_x(data.FPR(d))};\n",
       "        var h = geom.default_point_size;\n",
       "        var y = function(d) { return scale_y(data.TPR(d))};\n",
       "        // Define paths\n",
       "        var path = d3.line().x(x).y(y);\n",
       "        var splits = BrunelD3.makePathSplits(data, path, x);\n",
       "\n",
       "        // Define selection entry operations\n",
       "        function initialState(selection) {\n",
       "          selection\n",
       "            .attr('class', 'element line')\n",
       "        }\n",
       "\n",
       "        // Define selection update operations on merged data\n",
       "        function updateState(selection) {\n",
       "          selection\n",
       "            .attr('d', function(d) { return d.path });\n",
       "        }\n",
       "\n",
       "        // Define labeling for the selection\n",
       "        function label(selection, transitionMillis) {\n",
       "\n",
       "          var tooltipLabeling  = {\n",
       "            index: -1, method: 'path', location: ['center', 'center'], inside: true, align: 'middle', pad: 0, dy: 0.3,\n",
       "            fit: true, granularity: 0,\n",
       "            path: path,\n",
       "            content: function(d) {\n",
       "              return d.row == null ? null : '<span class=\"title\">FPR: </span>'\n",
       "\t\t\t+ '<span class=\"field\">' + data.FPR_f(d) + '</span>'\n",
       "\t\t\t+ '<br/>'\n",
       "\t\t\t+ '<span class=\"title\">TPR: </span>'\n",
       "\t\t\t+ '<span class=\"field\">' + data.TPR_f(d) + '</span>'\n",
       "            }\n",
       "          };\n",
       "          BrunelD3.addTooltip(selection, tooltipLabeling, geom);\n",
       "        }\n",
       "        // Create selections, set the initial state and transition updates\n",
       "        selection = main.selectAll('.element').data(splits, function(d) { return d.key });\n",
       "        var added = selection.enter().append('path');\n",
       "        merged = selection.merge(added);\n",
       "        initialState(added);\n",
       "        selection.filter(BrunelD3.hasData)\n",
       "          .classed('selected', BrunelD3.isSelected(data))\n",
       "          .filter(BrunelD3.isSelected(data)).raise();\n",
       "        updateState(BrunelD3.transition(merged, transitionMillis));\n",
       "        label(merged, transitionMillis);\n",
       "\n",
       "        BrunelD3.transition(selection.exit(), transitionMillis/3)\n",
       "          .style('opacity', 0.5).each( function() {\n",
       "            this.remove(); BrunelD3.removeLabels(this); \n",
       "        });\n",
       "      }\n",
       "\n",
       "      return {\n",
       "        data:           function() { return processed },\n",
       "        original:       function() { return original },\n",
       "        internal:       function() { return data },\n",
       "        selection:      function() { return merged },\n",
       "        makeData:       makeData,\n",
       "        build:          build,\n",
       "        chart:          function() { return charts[0] },\n",
       "        group:          function() { return elementGroup },\n",
       "        fields: {\n",
       "          x:            ['FPR'],\n",
       "          y:            ['TPR']\n",
       "        }\n",
       "      };\n",
       "    }();\n",
       "\n",
       "    function build(time, noData) {\n",
       "      var first = elements[0].data() == null;\n",
       "      if (first) time = 0;                                           // no transition for first call\n",
       "      buildAxes(time);\n",
       "      if ((first || time > -1) && !noData) {\n",
       "        elements[0].makeData();\n",
       "      }\n",
       "      elements[0].build(time);\n",
       "    }\n",
       "\n",
       "    // Expose the following components of the chart\n",
       "    return {\n",
       "      elements : elements,\n",
       "      interior : interior,\n",
       "      scales: {x:scale_x, y:scale_y},\n",
       "      zoom: function(params, time) {\n",
       "          if (params) zoom.on('zoom').call(zoomNode, params, time);\n",
       "          return d3.zoomTransform(zoomNode);\n",
       "      },\n",
       "      build : build\n",
       "    };\n",
       "    }();\n",
       "\n",
       "  function setData(rowData, i) { datasets[i||0] = BrunelD3.makeData(rowData) }\n",
       "  function updateAll(time) { charts.forEach(function(x) {x.build(time || 0)}) }\n",
       "  function buildAll() {\n",
       "    for (var i=0;i<arguments.length;i++) setData(arguments[i], i);\n",
       "    updateAll(transitionTime);\n",
       "  }\n",
       "\n",
       "  return {\n",
       "    dataPreProcess:     function(f) { if (f) pre = f; return pre },\n",
       "    dataPostProcess:    function(f) { if (f) post = f; return post },\n",
       "    data:               function(d,i) { if (d) setData(d,i); return datasets[i||0] },\n",
       "    visId:              visId,\n",
       "    build:              buildAll,\n",
       "    rebuild:            updateAll,\n",
       "    charts:             charts\n",
       "  }\n",
       "}\n",
       "\n",
       "// Data Tables /////////////////////////////////////////////////////////////////////////////////////\n",
       "\n",
       "var table1 = {\n",
       "   summarized: false,\n",
       "   names: ['FPR', 'TPR'], \n",
       "   options: ['numeric', 'numeric'], \n",
       "   rows: [[0, 0], [0.0008158, 0.0355097], [0.0022435, 0.0693013], [0.0038752, 0.10252],\n",
       "  [0.0055068, 0.1357388], [0.0085662, 0.1649485], [0.0097899, 0.1993127], [0.0124414, 0.2296678],\n",
       "  [0.014073, 0.2628866], [0.0161126, 0.2949599], [0.0181522, 0.3270332], [0.0195798, 0.3608247],\n",
       "  [0.0220273, 0.3917526], [0.0244748, 0.4226804], [0.0273302, 0.4524628], [0.0289619, 0.4856816],\n",
       "  [0.0316133, 0.5160367], [0.0338568, 0.5475372], [0.0371201, 0.5761741], [0.0387518, 0.6093929],\n",
       "  [0.0407914, 0.6414662], [0.042219, 0.6752577], [0.0446665, 0.7061856], [0.0458903, 0.7405498],\n",
       "  [0.0481338, 0.7720504], [0.0516011, 0.8001145], [0.0542525, 0.8304696], [0.0595554, 0.8533792],\n",
       "  [0.0654701, 0.8745704], [0.0722007, 0.8934708], [0.0799511, 0.9095074], [0.0887212, 0.9226804],\n",
       "  [0.0974913, 0.9358534], [0.1062615, 0.9490263], [0.1156435, 0.9604811], [0.1264532, 0.9679267],\n",
       "  [0.136651, 0.9770905], [0.1476647, 0.9839633], [0.1601061, 0.986827], [0.1723435, 0.9902635],\n",
       "  [0.1849888, 0.9925544], [0.198246, 0.9931271], [0.2115032, 0.9936999], [0.2243524, 0.9954181],\n",
       "  [0.2376096, 0.9959908], [0.2504589, 0.997709], [0.2635121, 0.9988545], [0.2765654, 1],\n",
       "  [0.2900265, 1], [0.3034877, 1], [0.3169488, 1], [0.33041, 1], [0.3438711, 1], [0.3573322, 1],\n",
       "  [0.3707934, 1], [0.3842545, 1], [0.3977157, 1], [0.4111768, 1], [0.424638, 1], [0.4380991, 1],\n",
       "  [0.4515603, 1], [0.4650214, 1], [0.4784826, 1], [0.4919437, 1], [0.5054049, 1], [0.518866, 1],\n",
       "  [0.5323271, 1], [0.5457883, 1], [0.5592494, 1], [0.5727106, 1], [0.5861717, 1], [0.5996329, 1],\n",
       "  [0.613094, 1], [0.6265552, 1], [0.6400163, 1], [0.6534775, 1], [0.6669386, 1], [0.6803998, 1],\n",
       "  [0.6938609, 1], [0.707322, 1], [0.7207832, 1], [0.7342443, 1], [0.7477055, 1], [0.7611666, 1],\n",
       "  [0.7746278, 1], [0.7880889, 1], [0.8015501, 1], [0.8150112, 1], [0.8284724, 1], [0.8419335, 1],\n",
       "  [0.8553947, 1], [0.8688558, 1], [0.8823169, 1], [0.8957781, 1], [0.9092392, 1], [0.9227004, 1],\n",
       "  [0.9361615, 1], [0.9496227, 1], [0.9630838, 1], [0.976545, 1], [0.9900061, 1], [1, 1], [1, 1]]\n",
       "};\n",
       "\n",
       "// Call Code to Build the system ///////////////////////////////////////////////////////////////////\n",
       "\n",
       "var v = new BrunelVis('visida724185d-e835-4d3d-8065-baac2dd3ffeb');\n",
       "v .build(table1);\n",
       "\n",
       "            \"\"\n",
       "        });\n",
       "        });\n",
       "        </script>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%brunel data('roc') x(FPR) y(TPR) line tooltip(#all) axes(x:'False Positive Rate':grid, y:'True Positive Rate':grid) title('ROC') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using RDD-based API for assessing performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+----------+\n",
      "|            features|       rawPrediction|         probability|prediction|\n",
      "+--------------------+--------------------+--------------------+----------+\n",
      "|[14219.0,1.0,5.0,...|[2.96268184396044...|[0.95085945671341...|       0.0|\n",
      "|[45306.0,1.0,5.0,...|[-0.2671103472660...|[0.43361663763690...|       1.0|\n",
      "|[15592.0,1.0,5.0,...|[1.59499556345547...|[0.83131778347299...|       0.0|\n",
      "|[9890.0,1.0,5.0,8...|[1.36018434894123...|[0.79578965761543...|       0.0|\n",
      "|[10138.0,1.0,5.0,...|[2.63844486284414...|[0.93329521417407...|       0.0|\n",
      "+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Prediction and the original labels\n",
      "(0.0,0.0)\n",
      "(1.0,1.0)\n",
      "(0.0,0.0)\n",
      "(0.0,0.0)\n",
      "(0.0,0.0)\n"
     ]
    }
   ],
   "source": [
    "import org.apache.spark.mllib.evaluation.MulticlassMetrics\n",
    "import org.apache.spark.mllib.regression.LabeledPoint\n",
    "\n",
    "\n",
    "val testDFWithPredictions = newModel.transform(testDF)\n",
    "testDFWithPredictions.select(\"features\", \"rawPrediction\", \"probability\", \"prediction\").show(5)\n",
    "\n",
    "// Compute raw scores on the test set\n",
    "val predictionAndLabels = testDFWithPredictions.select(\"prediction\", \"label\").\n",
    "                                                rdd.map { row =>\n",
    "  (row(0).asInstanceOf[Double], row(1).asInstanceOf[Double])\n",
    "}\n",
    "\n",
    "println(\"Prediction and the original labels\")\n",
    "predictionAndLabels.take(5).foreach(println)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC curve based on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "areaUnderROC: 0.9597124600638979\n",
      "best threashold:0.2589596552451625\n"
     ]
    }
   ],
   "source": [
    "val testData = testDFWithPredictions.drop(\"prediction\", \"rawPrediction\", \"probability\")\n",
    "val trainingSummary = lrModel.evaluate(testData)\n",
    "val binarySummary = trainingSummary.asInstanceOf[BinaryLogisticRegressionSummary]\n",
    "\n",
    "// The receiver-operating characteristic curve and area under the ROC curve\n",
    "val rocOnTestData = binarySummary.roc\n",
    "println(s\"areaUnderROC: ${binarySummary.areaUnderROC}\")\n",
    "\n",
    "// The threshold to maximize F-Measure\n",
    "val fMeasure = binarySummary.fMeasureByThreshold\n",
    "val maxFMeasure = fMeasure.select(max(\"F-Measure\")).head().getDouble(0)\n",
    "val bestThreshold = fMeasure.where(fMeasure(\"F-Measure\") === maxFMeasure).\n",
    "  select(\"threshold\").head().getDouble(0)\n",
    "println(s\"best threashold:${bestThreshold}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "         <link rel=\"stylesheet\" type=\"text/css\" href=\"/dsx-jupyter/ibmdsxuser-1010/1506603270372/nbextensions/brunel_ext/brunel.2.3.css\" charset=\"utf-8\">\n",
       "         <link rel=\"stylesheet\" type=\"text/css\" href=\"/dsx-jupyter/ibmdsxuser-1010/1506603270372/nbextensions/brunel_ext/sumoselect.css\" charset=\"utf-8\">\n",
       "         <style>  </style>\n",
       "         <div id=\"controlsId3a20b69b-32be-4c9c-a1f0-cb16a62a7697\" class=\"brunel\"/>\n",
       "<svg id=\"visid62ab5c93-0f07-4841-b16e-29fec4189656\" width=\"500\" height=\"400\"></svg>\n",
       "\n",
       "<script>\n",
       "require.config({\n",
       "            waitSeconds: 60,\n",
       "            paths: {\n",
       "                'd3': '//cdnjs.cloudflare.com/ajax/libs/d3/4.2.1/d3.min',\n",
       "                'topojson' : '//cdnjs.cloudflare.com/ajax/libs/topojson/1.6.20/topojson.min',\n",
       "                'brunel' : '/dsx-jupyter/ibmdsxuser-1010/1506603270372/nbextensions/brunel_ext/brunel.2.3.min',\n",
       "                'brunelControls' : '/dsx-jupyter/ibmdsxuser-1010/1506603270372/nbextensions/brunel_ext/brunel.controls.2.3.min'\n",
       "            },\n",
       "\n",
       "            shim: {\n",
       "               'brunel' : {\n",
       "                    exports: 'BrunelD3',\n",
       "                    deps: ['d3', 'topojson'],\n",
       "                    init: function() {\n",
       "                       return {\n",
       "                         BrunelD3 : BrunelD3,\n",
       "                         BrunelData : BrunelData\n",
       "                      }\n",
       "                    }\n",
       "                },\n",
       "               'brunelControls' : {\n",
       "                    exports: 'BrunelEventHandlers',\n",
       "                    init: function() {\n",
       "                       return {\n",
       "                         BrunelEventHandlers: BrunelEventHandlers,\n",
       "                         BrunelJQueryControlFactory: BrunelJQueryControlFactory\n",
       "                      }\n",
       "                    }\n",
       "                }\n",
       "\n",
       "            }\n",
       "\n",
       "        });\n",
       "\n",
       "        require([\"d3\"], function(d3) {\n",
       "        require([\"brunel\", \"brunelControls\"], function(brunel, brunelControls) {\n",
       "\n",
       "            function  BrunelVis(visId) {\n",
       "  \"use strict\";                                                                       // strict mode\n",
       "  var datasets = [],                                      // array of datasets for the original data\n",
       "      pre = function(d, i) { return d },                         // default pre-process does nothing\n",
       "      post = function(d, i) { return d },                       // default post-process does nothing\n",
       "      transitionTime = 200,                                        // transition time for animations\n",
       "      charts = [],                                                       // the charts in the system\n",
       "      vis = d3.select('#' + visId).attr('class', 'brunel');                     // the SVG container\n",
       "\n",
       "  BrunelD3.addDefinitions(vis);                                   // ensure standard symbols present\n",
       "\n",
       "  // Define chart #1 in the visualization //////////////////////////////////////////////////////////\n",
       "\n",
       "  charts[0] = function(parentNode, filterRows) {\n",
       "    var geom = BrunelD3.geometry(parentNode || vis.node(), 0, 0, 1, 1, 22, 43, 37, 13),\n",
       "      elements = [];                                              // array of elements in this chart\n",
       "\n",
       "    // Define groups for the chart parts ///////////////////////////////////////////////////////////\n",
       "\n",
       "    var chart =  vis.append('g').attr('class', 'chart1')\n",
       "      .attr('transform','translate(' + geom.chart_left + ',' + geom.chart_top + ')');\n",
       "    var overlay = chart.append('g').attr('class', 'element').attr('class', 'overlay');\n",
       "    var zoom = d3.zoom().scaleExtent([1/3,3]);\n",
       "    var zoomNode = overlay.append('rect').attr('class', 'overlay')\n",
       "      .attr('x', geom.inner_left).attr('y', geom.inner_top)\n",
       "      .attr('width', geom.inner_rawWidth).attr('height', geom.inner_rawHeight)\n",
       "      .style('cursor', 'move').call(zoom)\n",
       "      .node();\n",
       "    zoomNode.__zoom = d3.zoomIdentity;\n",
       "    chart.append('rect').attr('class', 'background').attr('width', geom.chart_right-geom.chart_left).attr('height', geom.chart_bottom-geom.chart_top);\n",
       "    var interior = chart.append('g').attr('class', 'interior zoomNone')\n",
       "      .attr('transform','translate(' + geom.inner_left + ',' + geom.inner_top + ')')\n",
       "      .attr('clip-path', 'url(#clip_visid62ab5c93-0f07-4841-b16e-29fec4189656_chart1_inner)');\n",
       "    interior.append('rect').attr('class', 'inner').attr('width', geom.inner_width).attr('height', geom.inner_height);\n",
       "    var gridGroup = interior.append('g').attr('class', 'grid');\n",
       "    var axes = chart.append('g').attr('class', 'axis')\n",
       "      .attr('transform','translate(' + geom.inner_left + ',' + geom.inner_top + ')');\n",
       "    vis.append('clipPath').attr('id', 'clip_visid62ab5c93-0f07-4841-b16e-29fec4189656_chart1_inner').append('rect')\n",
       "      .attr('x', 0).attr('y', 0)\n",
       "      .attr('width', geom.inner_rawWidth+1).attr('height', geom.inner_rawHeight+1);\n",
       "    chart.append('text').attr('class', 'title header').text('ROC').style('text-anchor', 'middle')\n",
       "      .attr('x','50%')\n",
       "      .attr('y',2).attr('dy','0.8em');\n",
       "\n",
       "    // Scales //////////////////////////////////////////////////////////////////////////////////////\n",
       "\n",
       "    var scale_x = d3.scaleLinear().domain([0, 1.0000001])\n",
       "      .range([0, geom.inner_width]);\n",
       "    var scale_inner = d3.scaleLinear().domain([0,1])\n",
       "      .range([-0.5, 0.5]);\n",
       "    var scale_y = d3.scaleLinear().domain([0, 1.0000001])\n",
       "      .range([geom.inner_height, 0]);\n",
       "    var base_scales = [scale_x, scale_y];                           // untransformed original scales\n",
       "\n",
       "    // Axes ////////////////////////////////////////////////////////////////////////////////////////\n",
       "\n",
       "    axes.append('g').attr('class', 'x axis')\n",
       "      .attr('transform','translate(0,' + geom.inner_rawHeight + ')')\n",
       "      .attr('clip-path', 'url(#clip_visid62ab5c93-0f07-4841-b16e-29fec4189656_chart1_haxis)');\n",
       "    vis.append('clipPath').attr('id', 'clip_visid62ab5c93-0f07-4841-b16e-29fec4189656_chart1_haxis').append('polyline')\n",
       "      .attr('points', '-1,-1000, -1,-1 -5,5, -1000,5, -100,1000, 10000,1000 10000,-1000');\n",
       "    axes.select('g.axis.x').append('text').attr('class', 'title').text('False Positive Rate').style('text-anchor', 'middle')\n",
       "      .attr('x',geom.inner_rawWidth/2)\n",
       "      .attr('y', geom.inner_bottom - 2.0).attr('dy','-0.27em');\n",
       "    axes.append('g').attr('class', 'y axis')\n",
       "      .attr('clip-path', 'url(#clip_visid62ab5c93-0f07-4841-b16e-29fec4189656_chart1_vaxis)');\n",
       "    vis.append('clipPath').attr('id', 'clip_visid62ab5c93-0f07-4841-b16e-29fec4189656_chart1_vaxis').append('polyline')\n",
       "      .attr('points', '-1000,-10000, 10000,-10000, 10000,' + (geom.inner_rawHeight+1) + ', -1,' + (geom.inner_rawHeight+1) + ', -1,' + (geom.inner_rawHeight+5) + ', -1000,' + (geom.inner_rawHeight+5) );\n",
       "    axes.select('g.axis.y').append('text').attr('class', 'title').text('True Positive Rate').style('text-anchor', 'middle')\n",
       "      .attr('x',-geom.inner_rawHeight/2)\n",
       "      .attr('y', 4-geom.inner_left).attr('dy', '0.7em').attr('transform', 'rotate(270)');\n",
       "\n",
       "    var axis_bottom = d3.axisBottom(scale_x).ticks(Math.min(10, Math.round(geom.inner_width / 33.0)));\n",
       "    var axis_left = d3.axisLeft(scale_y).ticks(Math.min(10, Math.round(geom.inner_width / 20)));\n",
       "\n",
       "    function buildAxes(time) {\n",
       "      var axis_x = axes.select('g.axis.x');\n",
       "      BrunelD3.transition(axis_x, time).call(axis_bottom.scale(scale_x));\n",
       "      var axis_y = axes.select('g.axis.y');\n",
       "      BrunelD3.transition(axis_y, time).call(axis_left.scale(scale_y));\n",
       "      BrunelD3.makeGrid(gridGroup, scale_x, geom.inner_height, true );\n",
       "      BrunelD3.makeGrid(gridGroup, scale_y, geom.inner_width, false );\n",
       "    }\n",
       "    zoom.on('zoom', function(t, time) {\n",
       "        t = t ||BrunelD3.restrictZoom(d3.event.transform, geom, this);\n",
       "        scale_x = t.rescaleX(base_scales[0]);\n",
       "        scale_y = t.rescaleY(base_scales[1]);\n",
       "        zoomNode.__zoom = t;\n",
       "        interior.attr('class', 'interior ' + BrunelD3.zoomLabel(t.k));;\n",
       "        build(time || -1);\n",
       "    });\n",
       "\n",
       "    // Define element #1 ///////////////////////////////////////////////////////////////////////////\n",
       "\n",
       "    elements[0] = function() {\n",
       "      var original, processed,                           // data sets passed in and then transformed\n",
       "        element, data,                                 // brunel element information and brunel data\n",
       "        selection, merged;                                      // d3 selection and merged selection\n",
       "      var elementGroup = interior.append('g').attr('class', 'element1'),\n",
       "        main = elementGroup.append('g').attr('class', 'main'),\n",
       "        labels = BrunelD3.undoTransform(elementGroup.append('g').attr('class', 'labels').attr('aria-hidden', 'true'), elementGroup);\n",
       "\n",
       "      function makeData() {\n",
       "        original = datasets[0];\n",
       "        if (filterRows) original = original.retainRows(filterRows);\n",
       "        processed = pre(original, 0)\n",
       "          .sortRows('FPR:ascending');\n",
       "        processed = post(processed, 0);\n",
       "        var f0 = processed.field('FPR'),\n",
       "          f1 = processed.field('TPR'),\n",
       "          f2 = processed.field('#row'),\n",
       "          f3 = processed.field('#selection');\n",
       "        var keyFunc = function(d) { return 'ALL' };\n",
       "        data = {\n",
       "          FPR:          function(d) { return f0.value(d.row) },\n",
       "          TPR:          function(d) { return f1.value(d.row) },\n",
       "          $row:         function(d) { return f2.value(d.row) },\n",
       "          $selection:   function(d) { return f3.value(d.row) },\n",
       "          FPR_f:        function(d) { return f0.valueFormatted(d.row) },\n",
       "          TPR_f:        function(d) { return f1.valueFormatted(d.row) },\n",
       "          $row_f:       function(d) { return f2.valueFormatted(d.row) },\n",
       "          $selection_f: function(d) { return f3.valueFormatted(d.row) },\n",
       "          _split:       function(d) { return 'ALL' },\n",
       "          _key:         keyFunc,\n",
       "          _rows:        BrunelD3.makeRowsWithKeys(keyFunc, processed.rowCount())\n",
       "        };\n",
       "      }\n",
       "\n",
       "      // Build element from data ///////////////////////////////////////////////////////////////////\n",
       "\n",
       "      function build(transitionMillis) {\n",
       "        element = elements[0];\n",
       "        var w = geom.default_point_size;\n",
       "        var x = function(d) { return scale_x(data.FPR(d))};\n",
       "        var h = geom.default_point_size;\n",
       "        var y = function(d) { return scale_y(data.TPR(d))};\n",
       "        // Define paths\n",
       "        var path = d3.line().x(x).y(y);\n",
       "        var splits = BrunelD3.makePathSplits(data, path, x);\n",
       "\n",
       "        // Define selection entry operations\n",
       "        function initialState(selection) {\n",
       "          selection\n",
       "            .attr('class', 'element line')\n",
       "        }\n",
       "\n",
       "        // Define selection update operations on merged data\n",
       "        function updateState(selection) {\n",
       "          selection\n",
       "            .attr('d', function(d) { return d.path });\n",
       "        }\n",
       "\n",
       "        // Define labeling for the selection\n",
       "        function label(selection, transitionMillis) {\n",
       "\n",
       "          var tooltipLabeling  = {\n",
       "            index: -1, method: 'path', location: ['center', 'center'], inside: true, align: 'middle', pad: 0, dy: 0.3,\n",
       "            fit: true, granularity: 0,\n",
       "            path: path,\n",
       "            content: function(d) {\n",
       "              return d.row == null ? null : '<span class=\"title\">FPR: </span>'\n",
       "\t\t\t+ '<span class=\"field\">' + data.FPR_f(d) + '</span>'\n",
       "\t\t\t+ '<br/>'\n",
       "\t\t\t+ '<span class=\"title\">TPR: </span>'\n",
       "\t\t\t+ '<span class=\"field\">' + data.TPR_f(d) + '</span>'\n",
       "            }\n",
       "          };\n",
       "          BrunelD3.addTooltip(selection, tooltipLabeling, geom);\n",
       "        }\n",
       "        // Create selections, set the initial state and transition updates\n",
       "        selection = main.selectAll('.element').data(splits, function(d) { return d.key });\n",
       "        var added = selection.enter().append('path');\n",
       "        merged = selection.merge(added);\n",
       "        initialState(added);\n",
       "        selection.filter(BrunelD3.hasData)\n",
       "          .classed('selected', BrunelD3.isSelected(data))\n",
       "          .filter(BrunelD3.isSelected(data)).raise();\n",
       "        updateState(BrunelD3.transition(merged, transitionMillis));\n",
       "        label(merged, transitionMillis);\n",
       "\n",
       "        BrunelD3.transition(selection.exit(), transitionMillis/3)\n",
       "          .style('opacity', 0.5).each( function() {\n",
       "            this.remove(); BrunelD3.removeLabels(this); \n",
       "        });\n",
       "      }\n",
       "\n",
       "      return {\n",
       "        data:           function() { return processed },\n",
       "        original:       function() { return original },\n",
       "        internal:       function() { return data },\n",
       "        selection:      function() { return merged },\n",
       "        makeData:       makeData,\n",
       "        build:          build,\n",
       "        chart:          function() { return charts[0] },\n",
       "        group:          function() { return elementGroup },\n",
       "        fields: {\n",
       "          x:            ['FPR'],\n",
       "          y:            ['TPR']\n",
       "        }\n",
       "      };\n",
       "    }();\n",
       "\n",
       "    function build(time, noData) {\n",
       "      var first = elements[0].data() == null;\n",
       "      if (first) time = 0;                                           // no transition for first call\n",
       "      buildAxes(time);\n",
       "      if ((first || time > -1) && !noData) {\n",
       "        elements[0].makeData();\n",
       "      }\n",
       "      elements[0].build(time);\n",
       "    }\n",
       "\n",
       "    // Expose the following components of the chart\n",
       "    return {\n",
       "      elements : elements,\n",
       "      interior : interior,\n",
       "      scales: {x:scale_x, y:scale_y},\n",
       "      zoom: function(params, time) {\n",
       "          if (params) zoom.on('zoom').call(zoomNode, params, time);\n",
       "          return d3.zoomTransform(zoomNode);\n",
       "      },\n",
       "      build : build\n",
       "    };\n",
       "    }();\n",
       "\n",
       "  function setData(rowData, i) { datasets[i||0] = BrunelD3.makeData(rowData) }\n",
       "  function updateAll(time) { charts.forEach(function(x) {x.build(time || 0)}) }\n",
       "  function buildAll() {\n",
       "    for (var i=0;i<arguments.length;i++) setData(arguments[i], i);\n",
       "    updateAll(transitionTime);\n",
       "  }\n",
       "\n",
       "  return {\n",
       "    dataPreProcess:     function(f) { if (f) pre = f; return pre },\n",
       "    dataPostProcess:    function(f) { if (f) post = f; return post },\n",
       "    data:               function(d,i) { if (d) setData(d,i); return datasets[i||0] },\n",
       "    visId:              visId,\n",
       "    build:              buildAll,\n",
       "    rebuild:            updateAll,\n",
       "    charts:             charts\n",
       "  }\n",
       "}\n",
       "\n",
       "// Data Tables /////////////////////////////////////////////////////////////////////////////////////\n",
       "\n",
       "var table1 = {\n",
       "   summarized: false,\n",
       "   names: ['FPR', 'TPR'], \n",
       "   options: ['numeric', 'numeric'], \n",
       "   rows: [[0, 0], [0.0015974, 0.035], [0.0039936, 0.0675], [0.0071885, 0.0975], [0.0087859, 0.1325],\n",
       "  [0.0111821, 0.165], [0.014377, 0.195], [0.0167732, 0.2275], [0.0191693, 0.26], [0.0215655, 0.2925],\n",
       "  [0.0247604, 0.3225], [0.0255591, 0.36], [0.0279553, 0.3925], [0.0303514, 0.425],\n",
       "  [0.0327476, 0.4575], [0.034345, 0.4925], [0.0367412, 0.525], [0.0391374, 0.5575],\n",
       "  [0.043131, 0.585], [0.0447284, 0.62], [0.0479233, 0.65], [0.048722, 0.6875], [0.0495208, 0.725],\n",
       "  [0.0495208, 0.765], [0.0511182, 0.8], [0.0535144, 0.8325], [0.0583067, 0.8575],\n",
       "  [0.0646965, 0.8775], [0.0726837, 0.8925], [0.0806709, 0.9075], [0.0854633, 0.9325],\n",
       "  [0.091853, 0.9525], [0.1014377, 0.9625], [0.1134185, 0.965], [0.1246006, 0.97], [0.1373802, 0.97],\n",
       "  [0.1485623, 0.975], [0.1597444, 0.98], [0.1701278, 0.9875], [0.1829073, 0.9875], [0.1948882, 0.99],\n",
       "  [0.206869, 0.9925], [0.2188498, 0.995], [0.2316294, 0.995], [0.2444089, 0.995],\n",
       "  [0.2563898, 0.9975], [0.2691693, 0.9975], [0.2819489, 0.9975], [0.2939297, 1], [0.3067093, 1],\n",
       "  [0.3194888, 1], [0.3322684, 1], [0.3450479, 1], [0.3578275, 1], [0.370607, 1], [0.3833866, 1],\n",
       "  [0.3961661, 1], [0.4089457, 1], [0.4217252, 1], [0.4345048, 1], [0.4472843, 1], [0.4600639, 1],\n",
       "  [0.4728435, 1], [0.485623, 1], [0.4984026, 1], [0.5111821, 1], [0.5239617, 1], [0.5367412, 1],\n",
       "  [0.5495208, 1], [0.5623003, 1], [0.5750799, 1], [0.5878594, 1], [0.600639, 1], [0.6134185, 1],\n",
       "  [0.6261981, 1], [0.6389776, 1], [0.6517572, 1], [0.6645367, 1], [0.6773163, 1], [0.6900958, 1],\n",
       "  [0.7028754, 1], [0.715655, 1], [0.7284345, 1], [0.7412141, 1], [0.7539936, 1], [0.7667732, 1],\n",
       "  [0.7795527, 1], [0.7923323, 1], [0.8051118, 1], [0.8178914, 1], [0.8306709, 1], [0.8434505, 1],\n",
       "  [0.85623, 1], [0.8690096, 1], [0.8817891, 1], [0.8945687, 1], [0.9073482, 1], [0.9201278, 1],\n",
       "  [0.9329073, 1], [0.9456869, 1], [0.9584665, 1], [0.971246, 1], [0.9840256, 1], [0.9968051, 1],\n",
       "  [1, 1], [1, 1]]\n",
       "};\n",
       "\n",
       "// Call Code to Build the system ///////////////////////////////////////////////////////////////////\n",
       "\n",
       "var v = new BrunelVis('visid62ab5c93-0f07-4841-b16e-29fec4189656');\n",
       "v .build(table1);\n",
       "\n",
       "            \"\"\n",
       "        });\n",
       "        });\n",
       "        </script>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%brunel data('rocOnTestData') x(FPR) y(TPR) line tooltip(#all) axes(x:'False Positive Rate':grid, y:'True Positive Rate':grid) title('ROC') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics (RDD-based API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val dtTestDFWithPredictions = newModel.transform(testDF)\n",
    "\n",
    "// Compute raw scores on the test set\n",
    "val dtPredictionAndLabels = dtTestDFWithPredictions.select(\"prediction\", \"label\").\n",
    "                                                rdd.map { row =>\n",
    "  (row(0).asInstanceOf[Double], row(1).asInstanceOf[Double])\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "1173.0  79.0   \n",
      "49.0    351.0  \n"
     ]
    }
   ],
   "source": [
    "import org.apache.spark.mllib.evaluation.MulticlassMetrics\n",
    "\n",
    "// Instantiate metrics object\n",
    "val dtMetrics = new MulticlassMetrics(dtPredictionAndLabels)\n",
    "\n",
    "// Confusion matrix\n",
    "println(\"Confusion matrix:\")\n",
    "println(dtMetrics.confusionMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics for the model\n",
      "Accuracy = 0.9225181598062954\n",
      "Precision(0.0) = 0.9599018003273322\n",
      "Precision(1.0) = 0.8162790697674419\n",
      "Recall(0.0) = 0.9369009584664537\n",
      "Recall(1.0) = 0.8775\n",
      "FPR(0.0) = 0.1225\n",
      "FPR(1.0) = 0.06309904153354633\n",
      "F1-Score(0.0) = 0.9482619240097009\n",
      "F1-Score(1.0) = 0.8457831325301205\n",
      "Weighted precision: 0.9251263207728793\n",
      "Weighted recall: 0.9225181598062955\n",
      "Weighted F1 score: 0.9234486573076233\n",
      "Weighted false positive rate: 0.10811720133984173\n"
     ]
    }
   ],
   "source": [
    "val dtAccuracy = dtMetrics.accuracy\n",
    "println(\"Statistics for the model\")\n",
    "println(s\"Accuracy = $dtAccuracy\")\n",
    "\n",
    "// Precision by label\n",
    "val dtLabels = dtMetrics.labels\n",
    "dtLabels.foreach { label =>\n",
    "  println(s\"Precision($label) = \" + dtMetrics.precision(label))\n",
    "}\n",
    "\n",
    "// Recall by label\n",
    "dtLabels.foreach { label =>\n",
    "  println(s\"Recall($label) = \" + dtMetrics.recall(label))\n",
    "}\n",
    "\n",
    "// False positive rate by label\n",
    "dtLabels.foreach { label =>\n",
    "  println(s\"FPR($label) = \" + dtMetrics.falsePositiveRate(label))\n",
    "}\n",
    "\n",
    "// F-measure by label\n",
    "dtLabels.foreach { label =>\n",
    "  println(s\"F1-Score($label) = \" + dtMetrics.fMeasure(label))\n",
    "}\n",
    "\n",
    "// Weighted statistics\n",
    "println(s\"Weighted precision: ${dtMetrics.weightedPrecision}\")\n",
    "println(s\"Weighted recall: ${dtMetrics.weightedRecall}\")\n",
    "println(s\"Weighted F1 score: ${dtMetrics.weightedFMeasure}\")\n",
    "println(s\"Weighted false positive rate: ${dtMetrics.weightedFalsePositiveRate}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Publish and create online deployments of model to both DSX Local and to WML service in Bluemix Cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publish to Cloud:  Save model to WML service in Bluemix Cloud\n",
    "*Publish and Deploy code based on the following documentation and examples:*\n",
    "\n",
    "https://apsportal.ibm.com/analytics/notebooks/c8652d2c-bfc9-4354-8168-f1c9f7f8dfc2/view?access_token=02a83fea8450a452c8de76af98dae078459d0f56810ddef4f4c62d5bc4fc72cf&cm_mc_uid=40662902271614933277870&cm_mc_sid_50200000=1503946544)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLF4J: Failed to load class \"org.slf4j.impl.StaticLoggerBinder\".\n",
      "SLF4J: Defaulting to no-operation (NOP) logger implementation\n",
      "SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.\n"
     ]
    }
   ],
   "source": [
    "// WML client library\n",
    "\n",
    "import com.ibm.analytics.ngp.repository._\n",
    "\n",
    "// Helper libraries\n",
    "\n",
    "import scalaj.http.{Http, HttpOptions}\n",
    "import scala.util.{Success, Failure}\n",
    "import java.util.Base64\n",
    "import java.nio.charset.StandardCharsets\n",
    "import play.api.libs.json._\n",
    "\n",
    "// Authenticate to Watson Machine Learning service on Bluemix.\n",
    "// These values come from \"Service Credentials\" tab in Bluemix WML service\n",
    "val service_path = \"https://ibm-watson-ml.mybluemix.net\"\n",
    "val instance_id = \"***\"\n",
    "val username = \"***\"\n",
    "val password = \"***\"\n",
    "\n",
    "\n",
    "val client = MLRepositoryClient(service_path)\n",
    "client.authorize(username, password)\n",
    "\n",
    "// Save model\n",
    "val model_artifact = MLRepositoryArtifact(newModel, trainingDF, \"From DSX Local: aPhone notebook-based ML Model\")\n",
    "val saved_model = client.models.save(model_artifact).get\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> Note: Class loading errors from logger can be ignored</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy in Cloud:  Create online deployment of published model in WML Bluemix Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HttpResponse({\"metadata\":{\"guid\":\"2be0035b-771b-4279-bea6-6798a2ea3f07\",\"url\":\"https://ibm-watson-ml.mybluemix.net/v3/wml_instances/fc65ecd2-a080-4f94-a7b8-40541f3fbc5c/published_models/7611f2d1-93c7-4825-8ab3-4be080eeee56/deployments/2be0035b-771b-4279-bea6-6798a2ea3f07\",\"created_at\":\"2017-09-28T18:17:37.981Z\",\"modified_at\":\"2017-09-28T18:17:39.206Z\"},\"entity\":{\"runtime_environment\":\"spark-2.0\",\"name\":\"From DSX Local:  Deployed aPhone notebook-based ML Model\",\"scoring_url\":\"https://ibm-watson-ml.mybluemix.net/v3/wml_instances/fc65ecd2-a080-4f94-a7b8-40541f3fbc5c/published_models/7611f2d1-93c7-4825-8ab3-4be080eeee56/deployments/2be0035b-771b-4279-bea6-6798a2ea3f07/online\",\"published_model\":{\"author\":{},\"name\":\"From DSX Local: aPhone notebook-based ML Model\",\"url\":\"https://ibm-watson-ml.mybluemix.net/v3/wml_instances/fc65ecd2-a080-4f94-a7b8-40541f3fbc5c/published_models/7611f2d1-93c7-4825-8ab3-4be080eeee56\",\"guid\":\"7611f2d1-93c7-4825-8ab3-4be080eeee56\",\"created_at\":\"2017-09-28T18:17:37.952Z\"},\"model_type\":\"sparkml-model-2.0\",\"status\":\"INITIALIZING\",\"type\":\"online\",\"deployed_version\":{\"url\":\"https://ibm-watson-ml.mybluemix.net/v2/artifacts/models/7611f2d1-93c7-4825-8ab3-4be080eeee56/versions/d7e734eb-3892-4ca0-b02d-201cca40b715\",\"guid\":\"d7e734eb-3892-4ca0-b02d-201cca40b715\",\"created_at\":\"2017-09-28T18:17:20.806Z\"}}},201,Map(Cache-Control -> Vector(no-cache, no-store, must-revalidate), Connection -> Vector(Keep-Alive), Content-Type -> Vector(application/json), Date -> Vector(Thu, 28 Sep 2017 18:17:39 GMT), Location -> Vector(https://ibm-watson-ml.mybluemix.net/v3/wml_instances/fc65ecd2-a080-4f94-a7b8-40541f3fbc5c/published_models/7611f2d1-93c7-4825-8ab3-4be080eeee56/deployments/2be0035b-771b-4279-bea6-6798a2ea3f07), Pragma -> Vector(no-cache), Server -> Vector(nginx/1.11.5), Status -> Vector(HTTP/1.1 201 Created), Transfer-Encoding -> Vector(chunked), X-Backside-Transport -> Vector(OK OK), X-Content-Type-Options -> Vector(nosniff), X-Global-Transaction-ID -> Vector(3625039247), X-Xss-Protection -> Vector(1; mode=block)))"
     ]
    }
   ],
   "source": [
    "// Reload saved model\n",
    "val model_version_href = saved_model.meta.prop(\"modelVersionHref\").get\n",
    "val loaded_model_artifact = client.models.version(model_version_href).get\n",
    "\n",
    "// Get WML service instance token\n",
    "val wml_auth_header = \"Basic \" + Base64.getEncoder.encodeToString((username + \":\" + password).getBytes(StandardCharsets.UTF_8))\n",
    "val wml_url = service_path + \"/v3/identity/token\"\n",
    "val wml_response = Http(wml_url).header(\"Authorization\", wml_auth_header).asString\n",
    "val wmltoken_json: JsValue = Json.parse(wml_response.body)\n",
    "\n",
    "val wmltoken = (wmltoken_json \\ \"token\").asOpt[String] match {\n",
    "    case Some(x) => x\n",
    "    case None => \"\"\n",
    "}\n",
    "wmltoken\n",
    "\n",
    "// Get published_models url from instance details\n",
    "val endpoint_instance = service_path + \"/v3/wml_instances/\" + instance_id\n",
    "val wml_response_instance = Http(endpoint_instance).header(\"Content-Type\", \"application/json\").header(\"Authorization\", \"Bearer \" + wmltoken).option(HttpOptions.connTimeout(10000)).option(HttpOptions.readTimeout(50000)).asString\n",
    "wml_response_instance\n",
    "val published_models_json: JsValue = Json.parse(wml_response_instance.body)\n",
    "val published_models_url = (((published_models_json \\ \"entity\") \\\\ \"published_models\")(0) \\ \"url\").as[JsString].value\n",
    "published_models_url\n",
    "\n",
    "//Get list of published models\n",
    "val wml_models = Http(published_models_url).header(\"Content-Type\", \"application/json\").header(\"Authorization\", \"Bearer \" + wmltoken).option(HttpOptions.connTimeout(10000)).option(HttpOptions.readTimeout(50000)).asString\n",
    "wml_models\n",
    "var deployment_endpoint: String = _\n",
    "wml_models.body.split(\"\\\"\").map{ s => {if ((s contains \"deployments\") & (s contains saved_model.uid.mkString)) {deployment_endpoint = s}}}\n",
    "deployment_endpoint\n",
    "\n",
    "//Create online deployment for published model\n",
    "val payload_name = \"From DSX Local:  Deployed aPhone notebook-based ML Model\"\n",
    "val payload_data_online = Json.stringify(Json.toJson(Map(\"type\" -> \"online\", \"name\" -> payload_name)))\n",
    "val response_online = Http(deployment_endpoint).postData(payload_data_online).header(\"Content-Type\", \"application/json\").header(\"Authorization\", \"Bearer \" + wmltoken).option(HttpOptions.connTimeout(50000)).option(HttpOptions.readTimeout(50000)).asString\n",
    "print (response_online)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Publish Locally - Save model to DSX Local ML service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "//DSX Local Machine Learning - Use Repository service to save model.\n",
    "\n",
    "import com.ibm.analytics.ngp.repository.MLRepositoryClient\n",
    "import com.ibm.analytics.ngp.repository.MLRepositoryArtifact\n",
    "\n",
    "val dsxl_repository_client = MLRepositoryClient()\n",
    "val model_artifact = MLRepositoryArtifact(newModel, trainingDF, \"From DSX Local: aPhone notebook-based ML Model\")\n",
    "\n",
    "//Add creater information for model\n",
    "val meta_with_author = model_artifact.meta.add(\"authorName\", \"Demo User\");\n",
    "val mutableArtifact = MLRepositoryArtifact.mutableModelArtifact(model_artifact);\n",
    "val new_artifact = mutableArtifact.mutate(newModel, meta_with_author);\n",
    "\n",
    "val saved_model = dsxl_repository_client.models.save(new_artifact).get\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy Locally:  Create online deployment of published model in DSX Local ML Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HttpResponse({\"metadata\":{\"guid\":\"81f751ec-d70e-49fc-b211-10ae34779eab\",\"href\":\"https://internal-nginx-svc.ibm-private-cloud.svc.cluster.local:12443/v2/deployments/81f751ec-d70e-49fc-b211-10ae34779eab\",\"createdAt\":\"2017-09-28T18:18:09.589Z\"},\"entity\":{\"name\":\"From DSX Local: Deployed aPhone notebook-based ML Model\",\"artifactVersion\":{\"guid\":\"1c587273-6375-4117-a934-fd8f53e04dc9\",\"href\":\"https://internal-nginx-svc.ibm-private-cloud.svc.cluster.local:12443/v2/artifacts/models/f363d532-8ea9-43aa-aa9f-0644bdebc368/versions/1c587273-6375-4117-a934-fd8f53e04dc9\"},\"predictionEndpoints\":{\"online\":\"https://internal-nginx-svc.ibm-private-cloud.svc.cluster.local:12443/v2/scoring/online/81f751ec-d70e-49fc-b211-10ae34779eab\",\"stream\":\"https://internal-nginx-svc.ibm-private-cloud.svc.cluster.local:12443/v2/deployments/81f751ec-d70e-49fc-b211-10ae34779eab/streams\",\"batch\":\"https://internal-nginx-svc.ibm-private-cloud.svc.cluster.local:12443/v2/deployments/81f751ec-d70e-49fc-b211-10ae34779eab/batch_jobs\"},\"modelType\":\"sparkml-model-2.0\",\"runtimeEnvironment\":\"spark-2.0\"}},201,Map(Connection -> Vector(keep-alive), Content-Length -> Vector(1058), Content-Type -> Vector(application/json), Date -> Vector(Thu, 28 Sep 2017 18:18:11 GMT), Location -> Vector(https://internal-nginx-svc.ibm-private-cloud.svc.cluster.local:12443/v2/deployments/81f751ec-d70e-49fc-b211-10ae34779eab), Server -> Vector(openresty), Status -> Vector(HTTP/1.1 201 Created)))"
     ]
    }
   ],
   "source": [
    "//DSX Local Machine Learning - Use Deployment service\n",
    "\n",
    "import play.api.libs.json._\n",
    "import scalaj.http.{Http, HttpOptions}\n",
    "\n",
    "val model_version_href = saved_model.meta.prop(\"modelVersionHref\").get\n",
    "val loaded_model_artifact = dsxl_repository_client.models.version(model_version_href).get\n",
    "\n",
    "val payload_artifactVersionHref = loaded_model_artifact.meta.prop(\"modelVersionHref\").get\n",
    "val payload_name = \"From DSX Local: Deployed aPhone notebook-based ML Model\"\n",
    "val payload_data_online = Json.stringify(Json.toJson(Map(\"artifactVersionHref\" -> payload_artifactVersionHref, \"name\" -> payload_name)))\n",
    "\n",
    "val service_path = \"https://internal-nginx-svc.ibm-private-cloud.svc.cluster.local:12443\"\n",
    "val online_path = service_path + \"/v2/deployments\"\n",
    "\n",
    "val response_online = Http(online_path).postData(payload_data_online).header(\"Content-Type\", \"application/json\").option(HttpOptions.connTimeout(10000)).option(HttpOptions.readTimeout(50000)).asString\n",
    "\n",
    "print (response_online)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Developed by Analytics Technology Acceleration Team, IBM Analytics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "file_extension": ".scala",
   "name": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
